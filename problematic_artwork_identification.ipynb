{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProblematicArtworkWorkflow.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMrw41LF9JPehsxu+eX89Gp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hturnbull93/problematic-artwork-identification/blob/master/problematic_artwork_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJm3NRpY5rz6",
        "colab_type": "text"
      },
      "source": [
        "# Problematic Artwork Workflow\n",
        "\n",
        "The aim of this project is to identify artworks in the UK (particularly statues/sculptures) that depict people related to or involved in the slave trade.\n",
        "\n",
        "## The Problems\n",
        "\n",
        "1. Getting a list of artworks in the UK.\n",
        "2. Identifying which of the artworks depicts a slaver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3UKQjRMyzNX",
        "colab_type": "text"
      },
      "source": [
        "## Getting Artworks\n",
        "\n",
        "The best source of the artworks comes from [ArtUK](https://artuk.org/). They don't have a public API, but do have an [infinite scrolling interface](https://artuk.org/discover/artworks/view_as/grid/search/work_type:sculpture) that loads in 20 artworks per \"page\". The [page for each artwork](https://artuk.org/discover/artworks/farmer-with-plough-244862/) contains details including title, artist, location and also images and descriptions for most of them (but not all). \n",
        "\n",
        "The strategy used was to collect the URLs from the infinite scroll page, then scrape the details from each artwork page in turn.\n",
        "\n",
        "To get the URLs a small bit of JavaScript was used to automate scrolling and collect and match for the right the URLs.\n",
        "\n",
        "```javascript\n",
        "// Locate and scroll to the pagination button, causing another set of artworks to load\n",
        "const scrollToButton = () => document.getElementsByClassName('pagination-btn')[0].scrollIntoView()\n",
        "\n",
        "// Attempt to scroll every second\n",
        "setInterval(scrollToButton, 1000)\n",
        "\n",
        "// When all are loaded manually stop the scrolling\n",
        "clearInterval(scrollToButton)\n",
        "\n",
        "// Get all the links (a tags) in the document and spread into an array\n",
        "const allLinks = [...document.links]\n",
        "\n",
        "// Map through to get their href attributes\n",
        "const allUrls = allLinks.map(link => link.href)\n",
        "\n",
        "// Remove duplicate URLs\n",
        "const uniqueUrls = [...new Set(allUrls)]\n",
        "\n",
        "// Regex match the URLs of interest. After the artworks path match any\n",
        "// combination that is not underscore until the next forward slash.\n",
        "const matcher = /https:\\/\\/artuk\\.org\\/discover\\/artworks\\/[^_]*\\//g\n",
        "const urls = uniqueUrls.join(\"\").match(matcher)\n",
        "\n",
        "// Create a csv data string and join the URLs with newlines \n",
        "const csvContent = 'data:text/csv;charset=utf-8,' + urls.join(\"\\n\")\n",
        "\n",
        "// Encode the csvContent as a URI\n",
        "const encodedUri = encodeURI(csvContent)\n",
        "\n",
        "// Create a link to download the csv\n",
        "const link = document.createElement(\"a\")\n",
        "link.setAttribute(\"href\", encodedUri)\n",
        "link.setAttribute(\"download\", \"artwork_urls.csv\")\n",
        "link.click()\n",
        "```\n",
        "\n",
        "The pagination runs out at 500 pages, so while it wasn't possible to scroll down the entire sculptures category directly, each subcategory was collected, then the main category approached with an a-z sort, then z-a, resulting in 21,225 unique URLs out of a total 24,379 artworks on the ArtUK sculpture section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oswYw-cU6KN6",
        "colab_type": "text"
      },
      "source": [
        "## Scraping Artwork Data\n",
        "\n",
        "A python script was used to scrape each artwork page for the title and artist.\n",
        "\n",
        "It uses the Requests library to get the html of the page, which is minified using the htmlmin library to remove excess whitespace, and then parsed using the BeautifulSoup library.\n",
        "\n",
        "The title and artist are attempted to be found using BeautifulSoup. If they cannot be found (if the request 404s for example) the url is marked as skipped.\n",
        "\n",
        "While the actual script read and wrote to csv for the full ~21,000 artworks, the following is an example using a sample list of artworks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSbS6W1L6fdd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "1fa22087-e350-4d42-855b-c075da93ff95"
      },
      "source": [
        "!pip install htmlmin\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "import htmlmin\n",
        "\n",
        "urlsCSV = [\n",
        "  [\"https://artuk.org/discover/artworks/farmer-with-plough-244862/\"],\n",
        "  [\"https://artuk.org/discover/artworks/adam-sedgwick-17851873-253304/\"],\n",
        "  [\"https://artuk.org/discover/artworks/napoleon-bonaparte-17691821-272365//\"],\n",
        "  [\"https://artuk.org/discover/artworks/tank-dreams-260202/\"],\n",
        "  [\"https://artuk.org/discover/artworks/spire-260987/\"],\n",
        "  [\"https://artuk.org/discover/artworks/the-divine-tragedy-256405/\"],\n",
        "  [\"https://artuk.org/discover/artworks/queen-mary-18671953-256643/\"],\n",
        "  [\"https://artuk.org/discover/artworks/bust-of-a-woman-256637/\"],\n",
        "  [\"https://artuk.org/discover/artworks/david-livingstone-18131873-266269/\"],\n",
        "  [\"https://artuk.org/discover/artworks/queen-alexandra-18441925-256650/\"],\n",
        "  [\"https://artuk.org/discover/artworks/clock-256663/\"],\n",
        "  [\"https://artuk.org/discover/artworks/bird-262955\"],\n",
        "  [\"https://artuk.org/discover/artworks/harris-academy-gates-248131/\"],\n",
        "  [\"https://artuk.org/discover/artworks/michelangelo-14751564-248503/\"],\n",
        "  [\"https://artuk.org/discover/artworks/spencer-perceval-17621812-prime-minister-253103/\"],\n",
        "  [\"https://artuk.org/discover/artworks/seated-woman-262034/\"],\n",
        "  [\"https://artuk.org/discover/artworks/pair-of-makonde-male-and-female-sculptures-261988/\"],\n",
        "  [\"https://artuk.org/discover/artworks/charles-mcgarel-17881876-252527/\"],\n",
        "  [\"https://artuk.org/discover/artworks/head-of-an-elderly-man-261990/\"],\n",
        "  [\"https://artuk.org/discover/artworks/henry-richard-18121888-272031/\"],\n",
        "  [\"https://artuk.org/discover/artworks/stone-table-252724/\"],\n",
        "  [\"https://artuk.org/discover/artworks/the-stone-sculptures-small-torso-252722/\"],\n",
        "  [\"https://artuk.org/discover/artworks/thors-hammer-252716/\"],\n",
        "  [\"https://artuk.org/discover/artworks/edward-colston-16361721-266037/\"]\n",
        "]\n",
        "\n",
        "artwork_url_title_artist = []\n",
        "\n",
        "for row in urlsCSV:\n",
        "  url = row[0]\n",
        "  r = requests.get(url)\n",
        "  minified = htmlmin.minify(r.text, remove_empty_space=True)\n",
        "  doc = BeautifulSoup(minified, 'html.parser')\n",
        "\n",
        "  try:\n",
        "    artwork_name = \" \".join(doc.h1.contents[0].split())\n",
        "    artist_name = doc.find_all(\"h2\", class_=\"artist\")[0].text.strip()\n",
        "    new_row = [url, artwork_name, artist_name]\n",
        "    artwork_url_title_artist.append(new_row)\n",
        "    print(new_row)\n",
        "  except:\n",
        "    error_row = [url, \"SKIPPED - ERROR\"]\n",
        "    artwork_url_title_artist.append(error_row)\n",
        "    print(error_row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting htmlmin\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Building wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=17d131a8ffd49f3502ce4c7f1544d94431689aa9c97e76a5c7bce85fb58dbd3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: htmlmin\n",
            "Successfully installed htmlmin-0.1.12\n",
            "['https://artuk.org/discover/artworks/farmer-with-plough-244862/', 'Farmer with Plough', 'Denise Delavigne']\n",
            "['https://artuk.org/discover/artworks/adam-sedgwick-17851873-253304/', 'Adam Sedgwick (1785â\\x80\\x931873)', 'Thomas Woolner (1825â\\x80\\x931892)']\n",
            "['https://artuk.org/discover/artworks/napoleon-bonaparte-17691821-272365//', 'Napoleon Bonaparte (1769â\\x80\\x931821)', 'Antoine-Denis Chaudet (1763â\\x80\\x931810)']\n",
            "['https://artuk.org/discover/artworks/tank-dreams-260202/', 'Tank Dreams', 'Anthony Hedgecock (b.1945)']\n",
            "['https://artuk.org/discover/artworks/spire-260987/', 'Spire', 'Victoria Rance (b.1959)']\n",
            "['https://artuk.org/discover/artworks/the-divine-tragedy-256405/', 'The Divine Tragedy', 'Robert Kiddey (1900â\\x80\\x931984)']\n",
            "['https://artuk.org/discover/artworks/queen-mary-18671953-256643/', 'Queen Mary (1867â\\x80\\x931953)', 'John Kirton (1878â\\x80\\x931948)']\n",
            "['https://artuk.org/discover/artworks/bust-of-a-woman-256637/', 'Bust of a Woman', 'John Kirton (1878â\\x80\\x931948)']\n",
            "['https://artuk.org/discover/artworks/david-livingstone-18131873-266269/', 'David Livingstone (1813â\\x80\\x931873)', 'unknown artist']\n",
            "['https://artuk.org/discover/artworks/queen-alexandra-18441925-256650/', 'Queen Alexandra (1844â\\x80\\x931925)', 'John Kirton (1878â\\x80\\x931948)']\n",
            "['https://artuk.org/discover/artworks/clock-256663/', 'Clock', 'John Kirton (1878â\\x80\\x931948)']\n",
            "['https://artuk.org/discover/artworks/bird-262955', 'Bird', 'Elisabeth Frink (1930â\\x80\\x931993)']\n",
            "['https://artuk.org/discover/artworks/harris-academy-gates-248131/', 'Harris Academy Gates', 'David Findlay Wilson (b.1962)']\n",
            "['https://artuk.org/discover/artworks/michelangelo-14751564-248503/', 'Michelangelo (1475â\\x80\\x931564)', 'unknown artist']\n",
            "['https://artuk.org/discover/artworks/spencer-perceval-17621812-prime-minister-253103/', 'Spencer Perceval (1762â\\x80\\x931812), Prime Minister', 'Joseph Nollekens (1737â\\x80\\x931823)']\n",
            "['https://artuk.org/discover/artworks/seated-woman-262034/', 'Seated Woman', 'Mario Negri (1916â\\x80\\x931987)']\n",
            "['https://artuk.org/discover/artworks/pair-of-makonde-male-and-female-sculptures-261988/', 'Pair of Makonde Male and Female Sculptures', 'unknown artist']\n",
            "['https://artuk.org/discover/artworks/charles-mcgarel-17881876-252527/', 'Charles McGarel (1788â\\x80\\x931876)', 'Hamo Thornycroft (1850â\\x80\\x931925)']\n",
            "['https://artuk.org/discover/artworks/head-of-an-elderly-man-261990/', 'Head of an Elderly Man', 'Joe Masoka']\n",
            "['https://artuk.org/discover/artworks/henry-richard-18121888-272031/', 'Henry Richard (1812â\\x80\\x931888)', 'Albert Toft (1862â\\x80\\x931949) and Thames Ditton']\n",
            "['https://artuk.org/discover/artworks/stone-table-252724/', 'Stone Table', 'BÃ¥rd Breivik (1948â\\x80\\x932016)']\n",
            "['https://artuk.org/discover/artworks/the-stone-sculptures-small-torso-252722/', 'The Stone Sculptures (Small Torso)', 'Kristian Blystad (b.1946)']\n",
            "['https://artuk.org/discover/artworks/thors-hammer-252716/', \"Thor's Hammer\", 'BÃ¥rd Breivik (1948â\\x80\\x932016)']\n",
            "['https://artuk.org/discover/artworks/edward-colston-16361721-266037/', 'Edward Colston (1636â\\x80\\x931721)', 'John Michael Rysbrack (1694â\\x80\\x931770)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvazU4SrFvGM",
        "colab_type": "text"
      },
      "source": [
        "## Finding Artworks Depicting Slavers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XRrk7sn4du7",
        "colab_type": "text"
      },
      "source": [
        "### NLP Name Query Strategy\n",
        "The initial strategy was to use natural language processing (NLP) to perform named entity recognition (NER) to detect names in the artwork titles, then query Wikipedia for an article matching that name and rate the article based on the number of occurences of the word \"slave\".\n",
        "\n",
        "For the NER, two libraries were considered: SpaCy and NLTK. In order to cast a wide net both were used and the resulting names made into a unique set. \n",
        "\n",
        "Each name found is queried in wikipedia using the wikipedia library. If an article for that name is found, then the number of \"slave\" occurences in the content is counted and recorded. If there is no article found a search is performed instead, and each of the articles in the search results are queried, casting an extra wide net in these cases. The idea is to reduce false negatives in the case that the name is a slaver, but there isn't an exact article of that name.\n",
        "\n",
        "As before, the actual script read and wrote to csv files. Additionally, as working through each of the ~21,000 artworks would take a considerable time, the original CSV is split into chunks of ~1,000 rows, each with its own thread to process them.\n",
        "\n",
        "The following script demonstrates the workflow taking the result of the previous script, but with with only 3 threads for chunks of 8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0oVppZ5YQ8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "f277c0ec-b964-41e6-b7e7-c1a6bf6de008"
      },
      "source": [
        "!pip install wikipedia\n",
        "import wikipedia\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "import re\n",
        "import threading\n",
        "import logging\n",
        "\n",
        "matcher = re.compile(\"slave\", re.IGNORECASE)\n",
        "\n",
        "# NLTK function\n",
        "def extract_entity_names(t):\n",
        "  entity_names = []\n",
        "\n",
        "  if hasattr(t, 'label') and t.label:\n",
        "    if t.label() == 'NE':\n",
        "      entity_names.append(' '.join([child[0] for child in t]))\n",
        "    else:\n",
        "      for child in t:\n",
        "        entity_names.extend(extract_entity_names(child))\n",
        "\n",
        "  return entity_names\n",
        "\n",
        "# Thread function\n",
        "def thread_function(name, chunk):\n",
        "  thread_name = f\"{name:02d}\"\n",
        "  chunk_length = f\"{len(chunk):04d}\"\n",
        "  print(f'Thread-{thread_name} starting', )\n",
        "\n",
        "  for original_row in chunk:\n",
        "    title = original_row[1]\n",
        "    names = []\n",
        "\n",
        "    # SpaCy Person match\n",
        "    doc = nlp(title)\n",
        "    names = [X.text for X in doc.ents if X.label_ == 'PERSON']\n",
        "\n",
        "    # NLTK name match \n",
        "    sentences = nltk.sent_tokenize(title)\n",
        "    tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
        "    tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
        "    chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
        "    for tree in chunked_sentences:\n",
        "      names.extend(extract_entity_names(tree))\n",
        "    \n",
        "    unique_names = (list(set(names)))\n",
        "\n",
        "    if len(unique_names) is 0:\n",
        "      this_row = original_row[:]\n",
        "      this_row.append(\"na - no names found\")\n",
        "      slave_matches.append(this_row)\n",
        "\n",
        "    if len(unique_names) > 0:\n",
        "      for name in unique_names:\n",
        "        try:\n",
        "          page = wikipedia.page(name)\n",
        "          result = len(matcher.findall(page.content))\n",
        "          this_row = original_row[:]\n",
        "          this_row.extend([\"direct\", name, page.url, result])\n",
        "          slave_matches.append(this_row)\n",
        "          if result > 0:\n",
        "            print(this_row)\n",
        "\n",
        "        except:\n",
        "          search = wikipedia.search(name)\n",
        "          search = [item for item in search if \"(disambiguation)\" not in item]\n",
        "          for item in search:\n",
        "            try:\n",
        "              page = wikipedia.page(item)\n",
        "              result = len(matcher.findall(page.content))\n",
        "              search_row = original_row[:]\n",
        "              search_row.extend([\"search\", name, page.url, result])\n",
        "              slave_matches.append(search_row)\n",
        "              if result > 0:\n",
        "                print(search_row)\n",
        "\n",
        "            except:\n",
        "              pass\n",
        "\n",
        "  print(f'Thread-{thread_name} done', )\n",
        "\n",
        "# Split input list into chunks\n",
        "def chunk(list, n):\n",
        "  for i in range(0, len(list), n):\n",
        "    yield list[i:i + n]\n",
        "\n",
        "chunks = list(chunk(artwork_url_title_artist, 8))\n",
        "\n",
        "threads = []\n",
        "\n",
        "slave_matches = []\n",
        "\n",
        "# Assign threads\n",
        "print(\"\\n==============================STARTING==============================\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "  x = threading.Thread(target=thread_function, args=(i, chunk,))\n",
        "  threads.append(x)\n",
        "  x.start()\n",
        "\n",
        "for i, thread in enumerate(threads):\n",
        "  thread.join()\n",
        "print(\"================================DONE================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "\n",
            "==============================STARTING==============================\n",
            "Thread-00 starting\n",
            "Thread-01 starting\n",
            "Thread-02 starting\n",
            "['https://artuk.org/discover/artworks/david-livingstone-18131873-266269/', 'David Livingstone (1813â\\x80\\x931873)', 'unknown artist', 'direct', 'David Livingstone', 'https://en.wikipedia.org/wiki/David_Livingstone', 35]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['https://artuk.org/discover/artworks/clock-256663/', 'Clock', 'John Kirton (1878â\\x80\\x931948)', 'direct', 'Clock', 'https://en.wikipedia.org/wiki/Clock', 3]\n",
            "['https://artuk.org/discover/artworks/adam-sedgwick-17851873-253304/', 'Adam Sedgwick (1785â\\x80\\x931873)', 'Thomas Woolner (1825â\\x80\\x931892)', 'direct', 'Adam Sedgwick', 'https://en.wikipedia.org/wiki/Adam_Sedgwick', 7]\n",
            "['https://artuk.org/discover/artworks/napoleon-bonaparte-17691821-272365//', 'Napoleon Bonaparte (1769â\\x80\\x931821)', 'Antoine-Denis Chaudet (1763â\\x80\\x931810)', 'direct', 'Napoleon Bonaparte', 'https://en.wikipedia.org/wiki/Napoleon', 15]\n",
            "['https://artuk.org/discover/artworks/harris-academy-gates-248131/', 'Harris Academy Gates', 'David Findlay Wilson (b.1962)', 'search', 'Harris Academy Gates', 'https://en.wikipedia.org/wiki/National_Treasure_(film_series)', 1]\n",
            "['https://artuk.org/discover/artworks/queen-mary-18671953-256643/', 'Queen Mary (1867â\\x80\\x931953)', 'John Kirton (1878â\\x80\\x931948)', 'search', 'Queen', 'https://en.wikipedia.org/wiki/Queen_Victoria', 1]\n",
            "['https://artuk.org/discover/artworks/michelangelo-14751564-248503/', 'Michelangelo (1475â\\x80\\x931564)', 'unknown artist', 'direct', 'Michelangelo', 'https://en.wikipedia.org/wiki/Michelangelo', 5]\n",
            "['https://artuk.org/discover/artworks/spencer-perceval-17621812-prime-minister-253103/', 'Spencer Perceval (1762â\\x80\\x931812), Prime Minister', 'Joseph Nollekens (1737â\\x80\\x931823)', 'direct', 'Spencer Perceval', 'https://en.wikipedia.org/wiki/Spencer_Perceval', 3]\n",
            "['https://artuk.org/discover/artworks/seated-woman-262034/', 'Seated Woman', 'Mario Negri (1916â\\x80\\x931987)', 'direct', 'Woman', 'https://en.wikipedia.org/wiki/Woman', 2]\n",
            "Thread-01 done\n",
            "['https://artuk.org/discover/artworks/pair-of-makonde-male-and-female-sculptures-261988/', 'Pair of Makonde Male and Female Sculptures', 'unknown artist', 'search', 'Female Sculptures', 'https://en.wikipedia.org/wiki/Sculpture', 3]\n",
            "Thread-00 done\n",
            "['https://artuk.org/discover/artworks/pair-of-makonde-male-and-female-sculptures-261988/', 'Pair of Makonde Male and Female Sculptures', 'unknown artist', 'search', 'Female Sculptures', 'https://en.wikipedia.org/wiki/Volubilis_(sculptures)', 1]\n",
            "['https://artuk.org/discover/artworks/charles-mcgarel-17881876-252527/', 'Charles McGarel (1788â\\x80\\x931876)', 'Hamo Thornycroft (1850â\\x80\\x931925)', 'direct', 'Charles', 'https://en.wikipedia.org/wiki/Charles', 1]\n",
            "['https://artuk.org/discover/artworks/charles-mcgarel-17881876-252527/', 'Charles McGarel (1788â\\x80\\x931876)', 'Hamo Thornycroft (1850â\\x80\\x931925)', 'direct', 'Charles McGarel', 'https://en.wikipedia.org/wiki/Charles_McGarel', 14]\n",
            "['https://artuk.org/discover/artworks/edward-colston-16361721-266037/', 'Edward Colston (1636â\\x80\\x931721)', 'John Michael Rysbrack (1694â\\x80\\x931770)', 'direct', 'Edward Colston', 'https://en.wikipedia.org/wiki/Edward_Colston', 16]\n",
            "Thread-02 done\n",
            "================================DONE================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz78r_xvAOSZ",
        "colab_type": "text"
      },
      "source": [
        "This approach does flag up the slaver traders/owners (in this set, Charles McGarel, Adam Sedgwick, and Edward Colston).\n",
        "\n",
        "In general, the combination of using NLTK which is less discriminatory in its NER resulting in names of things which aren't necescarily people, and the process of searching for the name and checking the returned articles seems to result in a significant number of fals positives. For example the artwork Clock has occurences of \"slave\" in reference to slave clocks that are synchronised by master clocks. Michaelangelo's article contains mentions of artworks he made with \"slave\" in their title (e.g. \"Rebellious Slave\"). Seated Woman and Queen Mary (depicting Mary of Teck) are picked by other articles from search that .\n",
        "\n",
        "It also picks up on David Livingston, Spencer Perceval who are both abolitionists. Interestingly querying the name of the other abolitionist, Henry Richard, finds a direct match to an article Richard Henry Lee, rather than the Henry Richard article that exists.\n",
        "\n",
        "In the above output, there are 13 results of interest (that is with at least 1 instance of the word \"slave\" in the found article), that correspond to 3 actual items of interest. These results still require manual investigation to sort out actual slave traders/owners from abolitionists, and when this workflow is scaled up to the full set would be quite an effort to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAuFyDbb4DHN",
        "colab_type": "text"
      },
      "source": [
        "### Levenshtein Distance Match to Known Slaver List Strategy\n",
        "\n",
        "It turns out that Wikipedia has a categories of [slave owners](https://en.wikipedia.org/wiki/Category:Slave_owners) and [slave traders](https://en.wikipedia.org/wiki/Category:Slave_traders), so a new strategy to check for the names of these known slavers. These article titles and URLs were collected using the following JavaScript on each of the category pages, and their subcategory pages. \n",
        "\n",
        "```javascript\n",
        "// Get each of the lists and spread into an array\n",
        "const lists = [...document.querySelectorAll('.mw-category-group ul')]\n",
        "\n",
        "// Map through the lists, mapping through each list to get its list item's url\n",
        "// and text (the name of the slaver), and flatten to a single array of arrays\n",
        "const allNamesUrls = lists.map(list => {\n",
        "  const listItems = [...list.children]\n",
        "  const nameAndUrl = listItems.map(item => {\n",
        "    const link = item.getElementsByTagName('a')[0]\n",
        "    return [link.text, link.href]\n",
        "  })\n",
        "  return nameAndUrl\n",
        "}).flat()\n",
        "\n",
        "// Filter out items that are links to other subcategories or to a list page.\n",
        "const urls = allNamesUrls.filter(item => {\n",
        "  return !(item[1].includes(\"Category\") || item[1].includes(\"List_of\"))\n",
        "})\n",
        "\n",
        "// Create a csv data string and join the URLs with newlines \n",
        "const csvContent = 'data:text/csv;charset=utf-8,' + urls.join(\"\\n\")\n",
        " \n",
        "// Encode the csvContent as a URI\n",
        "const encodedUri = encodeURI(csvContent)\n",
        " \n",
        "// Create a link to download the csv\n",
        "const link = document.createElement(\"a\")\n",
        "link.setAttribute(\"href\", encodedUri)\n",
        "link.setAttribute(\"download\", \"artwork_urls.csv\")\n",
        "link.click()\n",
        "```\n",
        "\n",
        "In total 1,117 slave owners and traders known to Wikipedia  were collected.\n",
        "\n",
        "Spacy and NLTK were used to extract the names from the resulting article titles in a similar manner to the process used to identify names in artwork titles, and for any that had more than one name found the most appropriate name to use was decided manually.\n",
        "\n",
        "The Levenshtein distance is a metric that measures how much one string would need to be edited to become another string, which is used here to provide a fuzzy match rather than an exact match in the case there there are slight differences in the way that the names are presented.\n",
        "\n",
        "The fuzzywuzzy library is used to calculate the Levenshtein distance from the artwork title (with dates in brackets removed) to each of the known slaver names, and records those with a rating of more than a certain threshold which is 80.\n",
        "\n",
        "As before, the actual script read and wrote to csv files and uses threads to work on each chunk chunks of ~1,000 rows. Each thread is also passed its own copy of the `known_slavers` list to prevent any possibility of there being conflict when attempting to access it.\n",
        "\n",
        "The following script demonstrates the workflow using the scraping results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wNHbOuBLSTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "ee3d159d-2dec-4515-d20b-d747f020747f"
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "!pip install python-Levenshtein\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "from fuzzywuzzy import fuzz\n",
        "import csv\n",
        "import re\n",
        "import threading\n",
        "\n",
        "# Known slaver owners and traders, URL, Title of article, best name\n",
        "known_slavers = [\n",
        "  ['https://en.wikipedia.org/wiki/John_Crenshaw', 'John Crenshaw', 'John Crenshaw'],\n",
        "  ['https://en.wikipedia.org/wiki/Edward_Colston', 'Edward Colston', 'Edward Colston'],\n",
        "  ['https://en.wikipedia.org/wiki/Pedro_Blanco_(slave_trader)', 'Pedro Blanco (slave trader)', 'Pedro Blanco'],\n",
        "  ['https://en.wikipedia.org/wiki/Francis_Baring,_3rd_Baron_Ashburton', 'Francis Baring, 3rd Baron Ashburton', 'Francis Baring'],\n",
        "  ['https://en.wikipedia.org/wiki/Adam_Sedgwick', 'Adam Sedgwick', 'Adam Sedgwick'],\n",
        "  ['https://en.wikipedia.org/wiki/Erasmus_W._Beck', 'Erasmus W. Beck', 'Erasmus W. Beck'],\n",
        "  ['https://en.wikipedia.org/wiki/William_McIntosh', 'William McIntosh', 'William McIntosh'],\n",
        "  ['https://en.wikipedia.org/wiki/Stephen_Delancey', 'Stephen Delancey', 'Stephen Delancey'],\n",
        "  ['https://en.wikipedia.org/wiki/Martin_Jenkins_Crawford', 'Martin Jenkins Crawford', 'Martin Jenkins Crawford'],\n",
        "  ['https://en.wikipedia.org/wiki/Charles_McGarel', 'Charles McGarel', 'Charles McGarel'],\n",
        "  ['https://en.wikipedia.org/wiki/James_Jackson_(congressman)', 'James Jackson (congressman)', 'James Jackson'],\n",
        "]\n",
        "\n",
        "# Thread function\n",
        "def thread_function(name, chunk, uris_names):\n",
        "  thread_name = f\"{name:02d}\"\n",
        "\n",
        "  for original_row in chunk:    \n",
        "    title = original_row[1]\n",
        "    treated_title = re.sub('\\(.*\\)','', title)\n",
        "\n",
        "    for name_row in uris_names:\n",
        "      name = name_row[2]\n",
        "      partial = fuzz.token_sort_ratio(name, treated_title)\n",
        "\n",
        "      if partial > 80:\n",
        "        this_row = original_row[:]\n",
        "        this_row.append(partial)\n",
        "        this_row.extend(name_row)\n",
        "        known_slaver_matches.append(this_row)\n",
        "        print(this_row)\n",
        "\n",
        "  print(f'Thread-{thread_name} done', )\n",
        "\n",
        "# Split input list into chunks\n",
        "def chunk(list, n):\n",
        "  for i in range(0, len(list), n):\n",
        "    yield list[i:i + n]\n",
        "\n",
        "chunks = list(chunk(artwork_url_title_artist, 8))\n",
        "\n",
        "threads = []\n",
        "\n",
        "known_slaver_matches = []\n",
        "\n",
        "# Assign threads\n",
        "print(\"\\n==============================STARTING==============================\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "  known_slavers_copy = known_slavers[:]\n",
        "\n",
        "  x = threading.Thread(target=thread_function, args=(i, chunk, known_slavers_copy,))\n",
        "  threads.append(x)\n",
        "  x.start()\n",
        "\n",
        "for i, thread in enumerate(threads):\n",
        "  thread.join()\n",
        "print(\"================================DONE================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.6/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (49.1.0)\n",
            "\n",
            "==============================STARTING==============================\n",
            "['https://artuk.org/discover/artworks/adam-sedgwick-17851873-253304/', 'Adam Sedgwick (1785â\\x80\\x931873)', 'Thomas Woolner (1825â\\x80\\x931892)', 100, 'https://en.wikipedia.org/wiki/Adam_Sedgwick', 'Adam Sedgwick', 'Adam Sedgwick']\n",
            "Thread-00 done\n",
            "Thread-01 done\n",
            "['https://artuk.org/discover/artworks/charles-mcgarel-17881876-252527/', 'Charles McGarel (1788â\\x80\\x931876)', 'Hamo Thornycroft (1850â\\x80\\x931925)', 100, 'https://en.wikipedia.org/wiki/Charles_McGarel', 'Charles McGarel', 'Charles McGarel']\n",
            "['https://artuk.org/discover/artworks/edward-colston-16361721-266037/', 'Edward Colston (1636â\\x80\\x931721)', 'John Michael Rysbrack (1694â\\x80\\x931770)', 100, 'https://en.wikipedia.org/wiki/Edward_Colston', 'Edward Colston', 'Edward Colston']\n",
            "Thread-02 done\n",
            "================================DONE================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waoPbcaZ-Heo",
        "colab_type": "text"
      },
      "source": [
        "This process successfully identifies all three slaver traders and owners in the sample data. While there are three exact matches here, with the entire set there are a few false positives where the subject of the artwork happens to have the same name (the date of birth and death do not match), and there are a few results where the names are simply similar, but are different names.\n",
        "\n",
        "In the full set, of the 64 matches with a 100 Levenshtein score, 9 are not the slavers (other people with the same name), and 55 are the correct matches.\n",
        "\n",
        "Of the 4 that are correct matches with sub 100 scores:\n",
        "\n",
        "| Score | Name | Note \n",
        "|---|---|---|\n",
        "| 92 | Simón Bolívar  | the artwork title did not have accented characters \n",
        "| 88 | Hadrian        | the artwork was titled \"Hadrianus\"                 \n",
        "| 88 | Robert Clayton | the artwork title includes his title \"Sir\"         \n",
        "| 81 | Julius Caeser  | the artwork title includes his praenomen (personal name) \"Gaius\"\n",
        "\n",
        "Of the total 59 artworks matched due to subjects being in more than one artwork 23 slaver traders/owners are depicted."
      ]
    }
  ]
}